{
  "do_train": true,
  "do_eval": true,

  "load_frame_features": true,
  
  "drop_path_rate": 0,
  "img_size": 224,
  "vit_model": "eva_clip_g",
  "q_former_model": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth",
  "use_grad_checkpoint": true,
  "vit_precision": "fp16",
    
  "num_epochs": 2,
  "learning_rate": 3e-5,
  "batch_size": 1,

  "freeze_vit": true,
  "freeze_qformer": false,
  "frozen_video_Qformer": false,
  "frozen_llama_proj": false,
  "freeze_s4v_proj": false,
  "freeze_crossattention": false,
  "crossattention_decoder": "sequential",

  "num_query_token": 32,
  "num_subsampled_frames": 8,
  "cross_attention_freq": 2,
  "llama_model": "meta-llama/Llama-2-7b-hf",
  "max_txt_len": 30,
  "end_sym": "\n",
  "low_resource": false,
  "device_8bit": 0,
  "num_workers": 4,

  "llama_proj_model": "",
  "fusion_header_type": "seqTransf",
  "max_frame_pos": 32,
  "fusion_head_layers": 2,
  "num_video_query_token": 32,
  
  "output_ckpt_path": "/location/to/save/ckpts/",
  "output_results_path": "/location/to/save/predictions/",

  "video_llama_cfg_path": "src/configs/video_llama/model_config.yaml",
  "model_type": "llama_v2",
  "gpu-id": 0,
  "options": null
}
  